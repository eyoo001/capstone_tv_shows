{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import wikipedia\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@Alexander_H/scraping-wikipedia-with-python-8000fc9c9e6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = pd.read_csv('./Untitled spreadsheet - Sheet1.csv')\n",
    "net_list = list(networks.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_American_Broadcasting_Company',\n",
       " 'https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_Adult_Swim',\n",
       " 'https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_A%26E',\n",
       " 'https://en.wikipedia.org/wiki/List_of_original_programs_distributed_by_Amazon',\n",
       " 'https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_AMC']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_American_Broadcasting_Company')\n",
    "b = BeautifulSoup(html.text, 'lxml')\n",
    "links = []\n",
    "\n",
    "for i in b.find_all(name = 'li'):\n",
    "    for link in i.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "links = links[77:]\n",
    "abc_links = ['https://en.wikipedia.org' + i for i in links]\n",
    "\n",
    "len(abc_links)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tv_titles = []\n",
    "tv_links = []\n",
    "\n",
    "\n",
    "for genre in net_list:\n",
    "    print(f'Collecting shows from {genre}')\n",
    "    html = requests.get(genre)\n",
    "    b = BeautifulSoup(html.text, 'lxml')\n",
    "    # get to the table on the page\n",
    "    for i in b.find_all(name='table', class_='wikitable'):\n",
    "        # get to the row of each show\n",
    "        for j in i.find_all(name='tr'):\n",
    "            #get just the title cell for each row.\n",
    "            # contains the title and the URL\n",
    "            for k in j.find_all(name='i'):\n",
    "                # get within that cell to just get the words\n",
    "                for link in k.find_all('a', href=True):\n",
    "                    # get the title and add to the list\n",
    "                    tv_titles.append(link['title'])\n",
    "                    # get the link and add to that list\n",
    "                    tv_links.append(link['href'])\n",
    "    #be a conscientious scraper and pause between scrapes\n",
    "    time.sleep(1)\n",
    "print(f'Number of TV Links Collected: {len(tv_links)}')\n",
    "print(f'Number of TV Titles Collected: {len(tv_titles)}')\n",
    "# remove film links that don't have a description page on Wikipedia\n",
    "new_tv_links = [i for i in tv_links if 'redlink' not in i]\n",
    "# same goes for titles\n",
    "new_tv_titles = [i for i in tv_titles if '(page does not exist)' not in i]\n",
    "print(f'Number of TV Links with Wikipedia Pages: {len(new_tv_links)}')\n",
    "print(f'Number of TV Titles with Wikipedia Pages: {len(new_tv_titles)}')\n",
    "#use this list to fetch from the API\n",
    "title_links = list(zip(new_tv_titles, new_tv_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Simpsons', 'American Dad!', 'Criminal Minds']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tv_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_Fox')\n",
    "b = BeautifulSoup(html.text, 'lxml')\n",
    "links = []\n",
    "\n",
    "for i in b.find_all(name = 'li'):\n",
    "    for link in i.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "links = links[57:]\n",
    "fox_links = ['https://en.wikipedia.org' + i for i in links]\n",
    "\n",
    "len(fox_links)\n",
    "# Need to remove cites, external links, related links, List links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_NBC')\n",
    "b = BeautifulSoup(html.text, 'lxml')\n",
    "links = []\n",
    "\n",
    "for i in b.find_all(name = 'li'):\n",
    "    for link in i.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "links = links[7:]\n",
    "nbc_links = ['https://en.wikipedia.org' + i for i in links]\n",
    "\n",
    "len(nbc_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_programs_broadcast_by_CBS')\n",
    "b = BeautifulSoup(html.text, 'lxml')\n",
    "links = []\n",
    "\n",
    "for i in b.find_all(name = 'li'):\n",
    "    for link in i.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "links = links[7:]\n",
    "cbs_links = ['https://en.wikipedia.org' + i for i in links]\n",
    "\n",
    "len(cbs_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"abc_links.pickle\",\"wb\") as fp:\n",
    "    pickle.dump(abc_links, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently have a list of wikis\n",
    "- Need to extract the show name (can be done simultaneously via the href title?)\n",
    "- Need to then take that list of names and use the wiki API to query the tables?? \n",
    "- NEED to grab: viewership information, logline\n",
    "- WANT to grab: writer, air date, rating, director, ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TVDV or Trakt API\n",
    "\n",
    "- Take the list of names from the wiki to return IDs\n",
    "- Use the IDs to grab the metadata\n",
    "- Combine the metadata with the wiki information in a dataframe\n",
    "- NEED: number of episodes, number of seasons, air date, producer, network, ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=jsonfm&formatversion=2&titles=List_of_Modern_Family_episodes\n",
    "\n",
    "https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=jsonfm&formatversion=2&titles=Grey%27s_Anatomy_(season_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two formats - List_of_SHOW_NAME_episodes & SHOW_NAME_(season_#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample API for wikipedia from https://www.mediawiki.org/wiki/API:Query#Sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

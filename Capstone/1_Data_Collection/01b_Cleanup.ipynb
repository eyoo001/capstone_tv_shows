{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the show list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I begin requesting information from the APIs, I'll want to clean the list that I have to be able to run it through the APIs first. \n",
    "\n",
    "In terms of the cleaning that's being performed, I am removing:\n",
    "- the leading url portion (that I had added in my first function...)\n",
    "- wikipedia formatting/categorizing links that were caught in my search\n",
    "- special characters and broken unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the list and cleaning the show names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./Assets_&_Data/amc_links.pickle', 'rb') as fp:\n",
    "    amc_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/as_links.pickle', 'rb') as fp:\n",
    "    as_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/cbs_links.pickle', 'rb') as fp:\n",
    "    cbs_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/cc_links.pickle', 'rb') as fp:\n",
    "    cc_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/cw_links.pickle', 'rb') as fp:\n",
    "    cw_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/disney_links.pickle', 'rb') as fp:\n",
    "    disney_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/fox_links.pickle', 'rb') as fp:\n",
    "    fox_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/hbo_links.pickle', 'rb') as fp:\n",
    "    hbo_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/nbc_links.pickle', 'rb') as fp:\n",
    "    nbc_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/syfy_links.pickle', 'rb') as fp:\n",
    "    syfy_links = pickle.load(fp)\n",
    "    \n",
    "with open ('./Assets_&_Data/abc_links.pickle', 'rb') as fp:\n",
    "    abc_links = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning links to be strings of show names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org#Drama_series',\n",
       " 'https://en.wikipedia.org#Science-fiction_series',\n",
       " 'https://en.wikipedia.org#Westerns',\n",
       " 'https://en.wikipedia.org#Game_shows_2',\n",
       " 'https://en.wikipedia.org#Miniseries']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('https://en.wikipedia.org/wiki/(.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wiki(link_list):\n",
    "    cleaned_links = [re.findall(pattern, x)[0] for x in link_list if re.findall(pattern, x)]\n",
    "    return cleaned_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_list = remove_wiki(hbo_links) + remove_wiki(nbc_links) +   \\\n",
    "            remove_wiki(amc_links) + remove_wiki(as_links) +    \\\n",
    "            remove_wiki(cbs_links) + remove_wiki(cc_links) +    \\\n",
    "            remove_wiki(cw_links) + remove_wiki(disney_links) + \\\n",
    "            remove_wiki(syfy_links) + remove_wiki(fox_links) + remove_wiki(abc_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9822"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(show_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_list = [x for x in show_list if not x.startswith('Template') \n",
    "         and not x.startswith('List of ') \n",
    "         and not x.startswith(\"Special:\")\n",
    "         and not x.startswith(\"Wikipedia:\")\n",
    "         and not x.startswith(\"Portal\")\n",
    "         and not x.startswith(\"IMDB\")\n",
    "         and not x.startswith(\"Talk:\")\n",
    "         and not x.startswith(\"Help:\")\n",
    "         and not x.startswith(\"Category\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(show_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game_of_Thrones',\n",
       " 'Westworld_(TV_series)',\n",
       " 'Big_Little_Lies_(TV_series)',\n",
       " 'The_Deuce_(TV_series)',\n",
       " 'Succession_(TV_series)',\n",
       " 'Curb_Your_Enthusiasm',\n",
       " 'Veep',\n",
       " 'Silicon_Valley_(TV_series)',\n",
       " 'Ballers',\n",
       " 'High_Maintenance']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    string = re.sub('_', ' ', string)           # Replaces underscores with spaces\n",
    "    string = re.sub('%27', '\\'', string)        # Replaces apostrophes\n",
    "    string = re.sub(' \\(([^)]+)\\)', '', string) # Removes the parentheses and the strings within them\n",
    "    string = re.sub('%26', '&', string)         # Replaces ampersands\n",
    "    string = re.sub('#', '', string)            # Removes hashes\n",
    "    string = re.sub('%3F', '?', string)         # Replaces question marks\n",
    "    string = re.sub('\\/', '', string)           # Removes forward slashes\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(link_list):\n",
    "    clean_list = [clean_string(x) for x in link_list]\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_show_list = clean_links(show_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Westworld',\n",
       " 'Big Little Lies',\n",
       " 'The Deuce',\n",
       " 'Succession',\n",
       " 'Curb Your Enthusiasm',\n",
       " 'Veep',\n",
       " 'Silicon Valley',\n",
       " 'Ballers',\n",
       " 'High Maintenance']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_show_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much better. Now that I have this cleaned list, I can load it into the other notebooks instead of the 9241 separate files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./Assets_&_Data/clean_show_list.pickle', 'wb') as fp:\n",
    "    pickle.dump(clean_show_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
